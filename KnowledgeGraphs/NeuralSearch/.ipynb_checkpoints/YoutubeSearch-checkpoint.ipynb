{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a23826",
   "metadata": {},
   "source": [
    "# Example of using Pinecode as embeddings DB for Neural Search of Youtube videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d2af5",
   "metadata": {},
   "source": [
    "## Load libraries and setup 3rd party applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7799aa4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googleapiclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build \u001b[38;5;66;03m# pip install --upgrade google-api-python-client\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'googleapiclient'"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build # pip install --upgrade google-api-python-client\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "from os.path import exists\n",
    "import os\n",
    "\n",
    "# !sudo apt update -y && sudo apt install ffmpeg -y\n",
    "#!pip install --upgrade protobuf\n",
    "#!pip install --upgrade tensorflow\n",
    "#!pip uninstall keras\n",
    "#!pip install --upgrade keras\n",
    "from pytube import YouTube  # !pip install pytube\n",
    "from pytube.exceptions import RegexMatchError\n",
    "import scrapetube\n",
    "import youtube_dl\n",
    "\n",
    "from tqdm.auto import tqdm  # !pip install tqdm\n",
    "\n",
    "import whisper # !pip install git+https://github.com/openai/whisper.git\n",
    "import torch  # pytorch install steps: pytorch.org\n",
    "\n",
    "import pinecone # pip install --upgrade pinecone-client\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab669815",
   "metadata": {},
   "source": [
    "## Define Inputs\n",
    "channel_names is a list of youtube channel names to index<br>\n",
    "pinecone_api_key and google_api_key requires free registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d32377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = './audio'\n",
    "channel_names = ['@promptmuse']\n",
    "pinecone_api_key = 'c65fa925-08e1-4af0-b08b-1104c6ffba25' # https://app.pinecone.io/projects\n",
    "google_api_key = 'AIzaSyAIIY6OsTws8dTfoyxNmJLmnfmH2f859Fw' # https://console.cloud.google.com/apis/dashboard\n",
    "\n",
    "youtube_dl_options = {\n",
    "    'skip_download': True,\n",
    "    'ignoreerrors': True\n",
    "}\n",
    "\n",
    "# name of Pinecone index to use\n",
    "index_id = \"audio\"\n",
    "# we encode and insert in batches of 64\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780940e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ed9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_video_in_channel(channel_id):\n",
    "    video_IDs = []\n",
    "    video_titles = {}\n",
    "    videos = scrapetube.get_channel(channel_id)\n",
    "\n",
    "    try:\n",
    "        for video in videos:\n",
    "            video_IDs.append(video['videoId'])\n",
    "            video_titles[video['videoId']] = video['title']['runs'][0]['text']\n",
    "    except:\n",
    "        with youtube_dl.YoutubeDL(youtube_dl_options) as ydl:\n",
    "            videos = ydl.extract_info(f'https://www.youtube.com/user/{channel_id}/videos')\n",
    "\n",
    "    if videos == None:\n",
    "        with youtube_dl.YoutubeDL(youtube_dl_options) as ydl:\n",
    "            videos = ydl.extract_info(f'https://www.youtube.com/{channel_id}/videos')        \n",
    "                \n",
    "    if videos != None:    \n",
    "        for item in videos['entries']:\n",
    "            video_IDs.append(item['id'])\n",
    "            video_titles[item['id']] = item['title']\n",
    "            \n",
    "    if len(video_IDs) == 0:\n",
    "        with youtube_dl.YoutubeDL(youtube_dl_options) as ydl:\n",
    "            videos = ydl.extract_info(f'https://www.youtube.com/channel/{channel_id}')\n",
    "        for item in videos['entries']:\n",
    "            video_IDs.append(item['id'])\n",
    "            video_titles[item['id']] = item['title']\n",
    "        \n",
    "    return video_IDs, video_titles\n",
    "        \n",
    "def get_youtube_channel_id(channel_name):\n",
    "    try:\n",
    "        youtube = build('youtube', 'v3', developerKey=google_api_key)\n",
    "        channels_response = youtube.channels().list(\n",
    "                forUsername=channel_name,\n",
    "                part=\"id, snippet, statistics, contentDetails, topicDetails\"\n",
    "        ).execute()\n",
    "        response = channels_response['items'][0]['id']\n",
    "        return response\n",
    "    except:\n",
    "        return channel_name\n",
    "\n",
    "def save_audio_from_videoIDs(save_path, video_IDs):\n",
    "    for videoID in tqdm(video_IDs):\n",
    "        check_file = f\"{save_path}/{videoID}.mp3\"\n",
    "        if exists(check_file):\n",
    "            continue\n",
    "\n",
    "        # url of video to be downloaded\n",
    "        url = f\"https://youtu.be/{videoID}\"\n",
    "\n",
    "        # try to create a YouTube vid object\n",
    "        try:\n",
    "            yt = YouTube(url)\n",
    "        except RegexMatchError:\n",
    "            print(f\"RegexMatchError for '{url}'\")\n",
    "            continue\n",
    "\n",
    "        itag = None\n",
    "        # we only want audio files\n",
    "        files = yt.streams.filter(only_audio=True)\n",
    "        for file in files:\n",
    "            # and of those audio files we grab the first audio for mp4 (eg mp3)\n",
    "            if file.mime_type == 'audio/mp4':\n",
    "                itag = file.itag\n",
    "                break\n",
    "        if itag is None:\n",
    "            # just incase no MP3 audio is found (shouldn't happen)\n",
    "            print(\"NO MP3 AUDIO FOUND\")\n",
    "            continue\n",
    "\n",
    "        # get the correct mp3 'stream'\n",
    "        stream = yt.streams.get_by_itag(itag)\n",
    "        # downloading the audio\n",
    "        try:\n",
    "            # only download mp3 if it does not exist\n",
    "            stream.download(output_path=save_path, filename=f\"{videoID}.mp3\")\n",
    "        except:\n",
    "            print(f\"error downloading audio for video ID {videoID}\")\n",
    "            \n",
    "def get_text_from_data(start, end, data):\n",
    "    text = \"\"\n",
    "    for i in range(start,end):\n",
    "        text += data[i]['text']+' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199bc60",
   "metadata": {},
   "source": [
    "## Initialize Whisper Model for transcription and Pinecone index\n",
    "Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51c2270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.4,\n",
       " 'namespaces': {'': {'vector_count': 805171}},\n",
       " 'total_vector_count': 805171}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model = whisper.load_model(\"small\").to(device)\n",
    "\n",
    "model_id = \"multi-qa-mpnet-base-dot-v1\"\n",
    "model_embed = SentenceTransformer(model_id)\n",
    "dim = model_embed.get_sentence_embedding_dimension()\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,  # app.pinecone.io\n",
    "    environment=\"us-west1-gcp\"\n",
    ")\n",
    "if index_id not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_id,\n",
    "        dim,\n",
    "        metric=\"dotproduct\"\n",
    "    )\n",
    "\n",
    "index = pinecone.Index(index_id)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e798e",
   "metadata": {},
   "source": [
    "## Create embeddings from youtube channel\n",
    "### Skip this step if channels are already indexed\n",
    "This takes a while to run as is it downloads and transcribes every video in the youtube channel<br>\n",
    "If videos do not download, try alternative methods as youtube channels are not setup consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c08b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@promptmuse\n",
      "@promptmuse\n",
      "[youtube:tab] @promptmuse: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unable to download webpage: HTTP Error 404: Not Found (caused by <HTTPError 404: 'Not Found'>); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see  https://yt-dl.org/update  on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] @promptmuse: Downloading webpage\n",
      "[download] Downloading playlist: Prompt Muse - Videos\n",
      "[youtube:tab] playlist Prompt Muse - Videos: Downloading 19 videos\n",
      "[download] Downloading video 1 of 19\n",
      "[youtube] FKoy7bncHLs: Downloading webpage\n",
      "[download] Downloading video 2 of 19\n",
      "[youtube] RI6ZLY2o900: Downloading webpage\n",
      "[download] Downloading video 3 of 19\n",
      "[youtube] 3wQBsFftbv8: Downloading webpage\n",
      "[download] Downloading video 4 of 19\n",
      "[youtube] XjObqq6we4U: Downloading webpage\n",
      "[download] Downloading video 5 of 19\n",
      "[youtube] xdE_h-xjMPs: Downloading webpage\n",
      "[download] Downloading video 6 of 19\n",
      "[youtube] 6ssyJx5CqjI: Downloading webpage\n",
      "[download] Downloading video 7 of 19\n",
      "[youtube] goRvGFs1sdc: Downloading webpage\n",
      "[download] Downloading video 8 of 19\n",
      "[youtube] Dq04W_sVZyk: Downloading webpage\n",
      "[youtube] Dq04W_sVZyk: Downloading MPD manifest\n",
      "[download] Downloading video 9 of 19\n",
      "[youtube] FLA6KCm4zLw: Downloading webpage\n",
      "[youtube] FLA6KCm4zLw: Downloading MPD manifest\n",
      "[download] Downloading video 10 of 19\n",
      "[youtube] jo--DkGakAI: Downloading webpage\n",
      "[youtube] jo--DkGakAI: Downloading MPD manifest\n",
      "[download] Downloading video 11 of 19\n",
      "[youtube] Geh2tk_4gc0: Downloading webpage\n",
      "[youtube] Geh2tk_4gc0: Downloading MPD manifest\n",
      "[download] Downloading video 12 of 19\n",
      "[youtube] mTpS59jTBRs: Downloading webpage\n",
      "[youtube] mTpS59jTBRs: Downloading MPD manifest\n",
      "[download] Downloading video 13 of 19\n",
      "[youtube] caBGryJg5KM: Downloading webpage\n",
      "[download] Downloading video 14 of 19\n",
      "[youtube] IAzobjisCKQ: Downloading webpage\n",
      "[youtube] IAzobjisCKQ: Downloading MPD manifest\n",
      "[download] Downloading video 15 of 19\n",
      "[youtube] FYXGXS6WFCQ: Downloading webpage\n",
      "[youtube] FYXGXS6WFCQ: Downloading MPD manifest\n",
      "[download] Downloading video 16 of 19\n",
      "[youtube] BVai4eT3xXQ: Downloading webpage\n",
      "[download] Downloading video 17 of 19\n",
      "[youtube] QKhLW02euIA: Downloading webpage\n",
      "[youtube] QKhLW02euIA: Downloading MPD manifest\n",
      "[download] Downloading video 18 of 19\n",
      "[youtube] 27l_TFWm6jM: Downloading webpage\n",
      "[youtube] 27l_TFWm6jM: Downloading MPD manifest\n",
      "[download] Downloading video 19 of 19\n",
      "[youtube] qcxps9tVM9M: Downloading webpage\n",
      "[youtube] qcxps9tVM9M: Downloading MPD manifest\n",
      "[download] Finished downloading playlist: Prompt Muse - Videos\n",
      "['FKoy7bncHLs', 'RI6ZLY2o900', '3wQBsFftbv8', 'XjObqq6we4U', 'xdE_h-xjMPs', '6ssyJx5CqjI', 'goRvGFs1sdc', 'Dq04W_sVZyk', 'FLA6KCm4zLw', 'jo--DkGakAI', 'Geh2tk_4gc0', 'mTpS59jTBRs', 'caBGryJg5KM', 'IAzobjisCKQ', 'FYXGXS6WFCQ', 'BVai4eT3xXQ', 'QKhLW02euIA', '27l_TFWm6jM', 'qcxps9tVM9M']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5feea400c42a99ea4b98f3008ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d3df596d424856876582a5ccdb3c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio/xdE_h-xjMPs.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2891c732c4148f3af7a2b6fda3b948d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8963ea536d4245e2bdd152913baed6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/xdE_h-xjMPs.mp3\n",
      "audio/XjObqq6we4U.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf660f149134a2b99383b80e694ea1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6642af9ebcae4d48819fefc910ca25ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/XjObqq6we4U.mp3\n",
      "audio/mTpS59jTBRs.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6550062b278439aab593aee313363a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4376fc42bb1b4996a2f36fc6ad356522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/mTpS59jTBRs.mp3\n",
      "audio/jo--DkGakAI.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7b5afde0a04cfb869f5c9de2d77a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dfdc2d7d254c9481eb5a870dd5726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/jo--DkGakAI.mp3\n",
      "audio/FLA6KCm4zLw.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc5ac3f72e9442ab440773a5b23513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8891fb248f435ab2c0e1d2c445f847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/FLA6KCm4zLw.mp3\n",
      "audio/qcxps9tVM9M.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ad0a12e73340d9849f14101573f905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47c6b601d784034953b20a1653b0b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/qcxps9tVM9M.mp3\n",
      "audio/FYXGXS6WFCQ.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413108e2e69341de98906bfaed1a8ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e175689ad543b9993829b9b581b902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/FYXGXS6WFCQ.mp3\n",
      "audio/RI6ZLY2o900.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4c338fdaac481f9fb616b978ec6840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e934b52be34f2a8471d456ecde69b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/RI6ZLY2o900.mp3\n",
      "audio/3wQBsFftbv8.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a564f26f2fb4cb18a8b28babdd687a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9cd3a32a164989bdcf13e3c73eb8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/3wQBsFftbv8.mp3\n",
      "audio/BVai4eT3xXQ.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a519935b723d481ba8d2fed4974dc610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27a9d49ec4a40259454bcfcc178d7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/BVai4eT3xXQ.mp3\n",
      "audio/QKhLW02euIA.mp3\n",
      "error, removing file  audio/QKhLW02euIA.mp3\n",
      "audio/6ssyJx5CqjI.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a949e6d6b2be455ab97dddc7ef9ed743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6da20c3aac4de5bb5c9ad46834aff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/6ssyJx5CqjI.mp3\n",
      "audio/IAzobjisCKQ.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6a7d225f8149f8a6e8bf14cef1bea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3144238b44924cacab31dbe9bbf4f15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/IAzobjisCKQ.mp3\n",
      "audio/goRvGFs1sdc.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b800e58578c4da989bb61e36b3adcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4bd872179547fcb1678a0719e541b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/goRvGFs1sdc.mp3\n",
      "audio/caBGryJg5KM.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618eeca27d6d49428dbe164d5d413fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea30d54b12024d7a849998284fe89068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/caBGryJg5KM.mp3\n",
      "audio/Geh2tk_4gc0.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3249bd95b50c4a818d50555b88bb6596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52afebd614a4d2099f8581e5f09b46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/Geh2tk_4gc0.mp3\n",
      "audio/27l_TFWm6jM.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d93d497d094e88b3697af0f1af19ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866f025b3fa44ac913b58b4aba21dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/27l_TFWm6jM.mp3\n",
      "audio/FKoy7bncHLs.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebed1d183ff24c40914853b19248ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79659b8492664cdaa2ad0ec1939998a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/FKoy7bncHLs.mp3\n",
      "audio/Dq04W_sVZyk.mp3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a5f15a4fc4658abd0a4fc32f174c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d026d07073f4027b8ab4af8feb1bc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing file  audio/Dq04W_sVZyk.mp3\n"
     ]
    }
   ],
   "source": [
    "for channel_name in channel_names:\n",
    "    try:\n",
    "        print(channel_name)\n",
    "        channel_id = get_youtube_channel_id(channel_name)\n",
    "        print(channel_id)\n",
    "        video_IDs, video_titles = get_all_video_in_channel(channel_id)\n",
    "        print(video_IDs)\n",
    "        save_audio_from_videoIDs(audio_dir, video_IDs)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # get list of MP3 audio files\n",
    "    paths = [str(x) for x in Path(audio_dir).glob('*.mp3')]\n",
    "    \n",
    "    transcriptions = []\n",
    "    for i, path in enumerate(tqdm(paths)):\n",
    "        _id = path.split('/')[-1][:-4]\n",
    "        # transcribe to get speech-to-text data\n",
    "        print(path)\n",
    "        try:\n",
    "            result = model.transcribe(path)\n",
    "        except:\n",
    "            print('error, removing file ',path)\n",
    "            os.remove(path)\n",
    "            continue\n",
    "        # add results to data list\n",
    "        transcriptions.extend(result['segments'])\n",
    "        \n",
    "        # set window (length of text chunk) and stride\n",
    "        window = 1\n",
    "        stride = 1  # smaller stride creates overlap\n",
    "        \n",
    "        data = []\n",
    "        results = []\n",
    "    \n",
    "        with open(\"transcription.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
    "            _id = path.split('/')[-1][:-4]\n",
    "            # transcribe to get speech-to-text data\n",
    "            result = model.transcribe(path)\n",
    "            segments = result['segments']\n",
    "            for j in range(0, len(segments), stride):\n",
    "                j_end = min(j+window, len(segments)-1)\n",
    "                text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n",
    "                start = segments[j]['start']\n",
    "                end = segments[j_end]['end']\n",
    "                row_id = f\"{_id}-t{segments[j]['start']}\"\n",
    "                meta = {\n",
    "                    **{\n",
    "                        \"id\": row_id,\n",
    "                        \"text\": text.strip(),\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"url\": f\"https://youtu.be/{_id}\",\n",
    "                        \"name\":_id,\n",
    "                        \"title\":video_titles[_id]\n",
    "                    }\n",
    "                }\n",
    "                data.append(meta)\n",
    "                json.dump(meta, fp)\n",
    "                fp.write('\\n')\n",
    "                    \n",
    "        new_data = []\n",
    "        \n",
    "        window = 6  # number of sentences to combine\n",
    "        stride = 3  # number of sentences to 'stride' over, used to create overlap\n",
    "        \n",
    "        for i in tqdm(range(0, len(data), stride)):\n",
    "            i_end = min(len(data)-1, i+window)\n",
    "            if data[i]['name'] != data[i_end]['name']:\n",
    "                # in this case we skip this entry as we have start/end of two videos\n",
    "                continue\n",
    "            text = get_text_from_data(i, i_end, data)\n",
    "            new_data.append({\n",
    "                'start': data[i]['start'],\n",
    "                'end': data[i_end]['end'],\n",
    "                'text': text,\n",
    "                'id': data[i]['id'],\n",
    "                'url': data[i]['url']+'?t='+str(int(data[i]['start'])),\n",
    "                \"name\":data[i]['name'],\n",
    "                \"title\":data[i]['title'],\n",
    "            })\n",
    "            \n",
    "        # loop through in batches of 64\n",
    "        index = pinecone.Index(index_id)\n",
    "        for j in tqdm(range(0, len(new_data), batch_size)):\n",
    "            # find end position of batch (for when we hit end of data)\n",
    "            j_end = min(len(new_data)-1, j+batch_size)\n",
    "            # extract the metadata like text, start/end positions, etc\n",
    "            batch_meta = [{\n",
    "                \"text\": new_data[x][\"text\"],\n",
    "                \"start\": new_data[x][\"start\"],\n",
    "                \"end\": new_data[x][\"end\"],\n",
    "                \"url\": new_data[x][\"url\"],\n",
    "                \"name\": new_data[x][\"name\"],\n",
    "                \"title\": new_data[x][\"title\"]\n",
    "            } for x in range(j, j_end)]\n",
    "            # extract only text to be encoded by embedding model\n",
    "            batch_text = [row['text'] for row in new_data[j:j_end]]\n",
    "            # create the embedding vectors\n",
    "            batch_embeds = model_embed.encode(batch_text).tolist()\n",
    "            # extract IDs to be attached to each embedding and metadata\n",
    "            batch_ids = [row['id'] for row in new_data[j:j_end]]\n",
    "            # 'upsert' (eg insert) IDs, embeddings, and metadata to index\n",
    "            try:\n",
    "                to_upsert = list(zip(batch_ids, batch_embeds, batch_meta))\n",
    "                index.upsert(to_upsert)\n",
    "            except:\n",
    "                continue\n",
    "        print('removing file ',path)\n",
    "        os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca2c58",
   "metadata": {},
   "source": [
    "## Query pinecone index for answer to question with video link in URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b7c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [{'id': 'My-I-6P_VUs-t676.68',\n",
      "              'metadata': {'end': 717.04,\n",
      "                           'name': 'My-I-6P_VUs',\n",
      "                           'start': 676.68,\n",
      "                           'text': \"using clip, what they're doing is they're \"\n",
      "                                   'using clip, which is a, you know, a model '\n",
      "                                   'that open AI released that they open AI '\n",
      "                                   'did not release sort of the generator '\n",
      "                                   'architecture on top of it. So the '\n",
      "                                   'community has, has kind of taken that and '\n",
      "                                   'applied another generator called DQ GAN. '\n",
      "                                   \"And so it's not even just taking one model \"\n",
      "                                   \"and changing the data set you're working \"\n",
      "                                   \"on, it's taking two models and then \"\n",
      "                                   'recomposing them in a really interesting '\n",
      "                                   \"way. So yeah, so I don't think we know \"\n",
      "                                   'exactly what the form factor is, but you '\n",
      "                                   'know, when ',\n",
      "                           'title': 'Compositional ML and the Future of '\n",
      "                                    'Software Development with Dillon Erb - '\n",
      "                                    '#520',\n",
      "                           'url': 'https://youtu.be/My-I-6P_VUs?t=676'},\n",
      "              'score': 28.9160156,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'eJ4IeChWVz0-t1517.68',\n",
      "              'metadata': {'end': 1548.96,\n",
      "                           'name': 'eJ4IeChWVz0',\n",
      "                           'start': 1517.68,\n",
      "                           'text': \"Yeah, why don't you take a few moments to \"\n",
      "                                   'more deeply introduce Clip and why you '\n",
      "                                   'think it was so exciting? Clip is this '\n",
      "                                   'work from the OpenAI team. And basically, '\n",
      "                                   \"there's a lot of technical content that I \"\n",
      "                                   'will not spend time describing here. But '\n",
      "                                   'big picture is that they wanted ',\n",
      "                           'title': 'Trends in Computer Vision with Georgia '\n",
      "                                    'Gkioxari - #549',\n",
      "                           'url': 'https://youtu.be/eJ4IeChWVz0?t=1517'},\n",
      "              'score': 28.1160984,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'HNJPasJUGqs-t262.84',\n",
      "              'metadata': {'end': 295.76,\n",
      "                           'name': 'HNJPasJUGqs',\n",
      "                           'start': 262.84,\n",
      "                           'text': \"Adversarial attacks. We know that OpenAI's \"\n",
      "                                   'clip responds to photos and drawings of '\n",
      "                                   \"the same thing, so let's try some nasty \"\n",
      "                                   'attacks involving combining the two. When '\n",
      "                                   'we give it these images, it can classify '\n",
      "                                   'them with ease. This is an apple, this is '\n",
      "                                   'a laptop, a mug, and so on. Nothing too '\n",
      "                                   'crazy going on here. ',\n",
      "                           'title': 'Do Neural Networks Think Like Our Brain? '\n",
      "                                    'OpenAI Answers! ðŸ§ ',\n",
      "                           'url': 'https://youtu.be/HNJPasJUGqs?t=262'},\n",
      "              'score': 26.884819,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'zmlHI2kAqmk-t115.84',\n",
      "              'metadata': {'end': 157.96,\n",
      "                           'name': 'zmlHI2kAqmk',\n",
      "                           'start': 115.84,\n",
      "                           'text': \"Now we're seeing, I think, even a step \"\n",
      "                                   'beyond that which is, in the case of this '\n",
      "                                   'creative artistic community using Clip, '\n",
      "                                   \"what they're doing is they're using Clip, \"\n",
      "                                   'which is a model that OpenAI released that '\n",
      "                                   'they open AI did not release the generator '\n",
      "                                   'architecture on top of it. The community '\n",
      "                                   'has taken that and applied another '\n",
      "                                   \"generator called VQGAN. It's not even just \"\n",
      "                                   'taking one model and changing the data set '\n",
      "                                   \"you're working on. \",\n",
      "                           'title': 'Evolution of Machine Learning as a SWE '\n",
      "                                    'Discipline - Clips - #520',\n",
      "                           'url': 'https://youtu.be/zmlHI2kAqmk?t=115'},\n",
      "              'score': 26.7587776,\n",
      "              'sparseValues': {},\n",
      "              'values': []},\n",
      "             {'id': 'eJ4IeChWVz0-t1506.84',\n",
      "              'metadata': {'end': 1536.44,\n",
      "                           'name': 'eJ4IeChWVz0',\n",
      "                           'start': 1506.84,\n",
      "                           'text': \"And that's what they showed. They showed \"\n",
      "                                   'that that creates a great representation '\n",
      "                                   \"if you're trying to jointly capture text \"\n",
      "                                   \"with images. Yeah, why don't you take a \"\n",
      "                                   'few moments to more deeply introduce Clip '\n",
      "                                   'and why you think it was so exciting? Clip '\n",
      "                                   'is this work from the OpenAI team. ',\n",
      "                           'title': 'Trends in Computer Vision with Georgia '\n",
      "                                    'Gkioxari - #549',\n",
      "                           'url': 'https://youtu.be/eJ4IeChWVz0?t=1506'},\n",
      "              'score': 26.3277893,\n",
      "              'sparseValues': {},\n",
      "              'values': []}],\n",
      " 'namespace': ''}\n"
     ]
    }
   ],
   "source": [
    "# Define the query or question to ask\n",
    "query = \"what is OpenAI's CLIP?\"\n",
    "# Create and embedding representing the question\n",
    "xq = model_embed.encode(query).tolist()\n",
    "# Search the index for the top (k) answers \n",
    "results = index.query(xq, top_k=5, include_metadata=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801530b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
